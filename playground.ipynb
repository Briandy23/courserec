{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from recbole.config import Config\n",
    "from recbole.utils import init_seed, get_model, get_trainer\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from recbole.data.interaction import Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.baselines.baseline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config/Pop.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mrecbolemoocube\u001b[0m\n",
      "\u001b[1;34mThe number of users\u001b[0m: 6508\n",
      "\u001b[1;34mAverage actions of users\u001b[0m: 14.941293991086523\n",
      "\u001b[1;34mThe number of items\u001b[0m: 688\n",
      "\u001b[1;34mAverage actions of items\u001b[0m: 141.51819505094613\n",
      "\u001b[1;34mThe number of inters\u001b[0m: 97223\n",
      "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 97.8286339889367%\n",
      "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id']\n"
     ]
    }
   ],
   "source": [
    "model_name, config = load_config(config_file)\n",
    "init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "\n",
    "dataset = create_dataset(config)\n",
    "print(dataset)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "all_valid_results = dict()\n",
    "all_test_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@10\n"
     ]
    }
   ],
   "source": [
    "model = get_model(model_name)(config, train_data._dataset).to(config[\"device\"])\n",
    "trainer = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])(config, model)\n",
    "print(config[\"valid_metric\"])\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_and_interactions(model, test_data):\n",
    "    num_items = test_data._dataset.item_num\n",
    "    num_users = test_data._dataset.user_num\n",
    "    topk_matches = defaultdict(list)\n",
    "    interactions = defaultdict(list)\n",
    "    model.to(\"cpu\")\n",
    "    for user_id in range(1, num_users):\n",
    "        row = test_data._dataset.inter_matrix().getrow(user_id).nonzero()[1]\n",
    "        interactions[user_id] = row.tolist()\n",
    "        tmp = Interaction({\"user_id\":[user_id for i in range(num_items)],\"item_id\":[i for i in range(num_items)]})\n",
    "        prediction = model.predict(tmp).cpu().detach().numpy().argsort()[-10:][::-1].tolist()\n",
    "        topk_matches[user_id] = prediction\n",
    "    return topk_matches, interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_matches, interactions = get_topk_and_interactions(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG=2.711 |  Recall=5.073 | HR=9.728 | Precision=0.993 | HR@1=0.830 | HR@3=2.905 | HR@5=4.549 | Computed for all users.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9927770093745196, 5.073329352374995, 2.710929954486078, 9.727985246657447)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(topk_matches, interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG=2.711 |  Recall=5.073 | HR=9.728 | Precision=0.993 | HR@1=0.830 | HR@3=2.905 | HR@5=4.549 | Computed for all users.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9927770093745196, 5.073329352374995, 2.710929954486078, 9.727985246657447)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(topk_matches, test_user_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(topk_matches, test_user_products):\n",
    "    \"\"\"Compute metrics for predicted recommendations.\n",
    "    Args:\n",
    "        topk_matches: a list or dict of product ids in ascending order.\n",
    "    \"\"\"\n",
    "    # Compute metrics\n",
    "    precisions_all, recalls_all, ndcgs_all, hits_all, hits_at_1_all, hits_at_3_all, hits_at_5_all = [], [], [], [], [], [], []\n",
    "    test_user_idxs = list(test_user_products.keys())\n",
    "    for uid in test_user_idxs:\n",
    "        pred_list, rel_set = topk_matches.get(uid, [])[::-1], test_user_products[uid]\n",
    "        if len(pred_list) == 0:\n",
    "            ndcgs_all.append(0.0)\n",
    "            recalls_all.append(0.0)\n",
    "            precisions_all.append(0.0)\n",
    "            hits_all.append(0.0)\n",
    "            hits_at_1_all.append(0.0)\n",
    "            hits_at_3_all.append(0.0)\n",
    "            hits_at_5_all.append(0.0)\n",
    "            continue\n",
    "\n",
    "        dcg_all = 0.0\n",
    "        hit_num_all = 0.0\n",
    "        hit_at_1_all = 0.0\n",
    "        hit_at_3_all = 0.0\n",
    "        hit_at_5_all = 0.0\n",
    "        for i in range(len(pred_list)):\n",
    "            if pred_list[i] in rel_set:\n",
    "                dcg_all += 1. / (np.log(i + 2) / np.log(2))\n",
    "                hit_num_all += 1\n",
    "                if i < 1:\n",
    "                    hit_at_1_all += 1\n",
    "                if i < 3:\n",
    "                    hit_at_3_all += 1\n",
    "                if i < 5:\n",
    "                    hit_at_5_all += 1\n",
    "        # idcg\n",
    "        idcg_all = 0.0\n",
    "        for i in range(min(len(rel_set), len(pred_list))):\n",
    "            idcg_all += 1. / (np.log(i + 2) / np.log(2))\n",
    "        ndcg_all = dcg_all / idcg_all\n",
    "        recall_all = hit_num_all / len(rel_set)\n",
    "        precision_all = hit_num_all / len(pred_list)\n",
    "        hit_all = 1.0 if hit_num_all > 0.0 else 0.0\n",
    "        hit_at_1_all = 1.0 if hit_at_1_all > 0.0 else 0.0\n",
    "        hit_at_3_all = 1.0 if hit_at_3_all > 0.0 else 0.0\n",
    "        hit_at_5_all = 1.0 if hit_at_5_all > 0.0 else 0.0\n",
    "        ndcgs_all.append(ndcg_all)\n",
    "        recalls_all.append(recall_all)\n",
    "        precisions_all.append(precision_all)\n",
    "        hits_all.append(hit_all)\n",
    "        hits_at_1_all.append(hit_at_1_all)\n",
    "        hits_at_3_all.append(hit_at_3_all)\n",
    "        hits_at_5_all.append(hit_at_5_all)\n",
    "\n",
    "    avg_precision_all = np.mean(precisions_all) * 100\n",
    "    avg_recall_all = np.mean(recalls_all) * 100\n",
    "    avg_ndcg_all = np.mean(ndcgs_all) * 100\n",
    "    avg_hit_all = np.mean(hits_all) * 100\n",
    "    avg_hit_at_1_all = np.mean(hits_at_1_all) * 100\n",
    "    avg_hit_at_3_all = np.mean(hits_at_3_all) * 100\n",
    "    avg_hit_at_5_all = np.mean(hits_at_5_all) * 100\n",
    "\n",
    "    print('NDCG={:.3f} |  Recall={:.3f} | HR={:.3f} | Precision={:.3f} | HR@1={:.3f} | HR@3={:.3f} | HR@5={:.3f} \\n'.format(\n",
    "            avg_ndcg_all, avg_recall_all, avg_hit_all, avg_precision_all, avg_hit_at_1_all, avg_hit_at_3_all, avg_hit_at_5_all))\n",
    "\n",
    "    return avg_precision_all, avg_recall_all, avg_ndcg_all, avg_hit_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a/b/c'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"a\", \"b\", \"c\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upgpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
